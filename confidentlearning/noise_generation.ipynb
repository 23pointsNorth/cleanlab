{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Generation\n",
    "\n",
    "#### Contains methods for generating valid (learning with noise is possible) noise matrices, generating noisy labels given a noise matrix, generating valid noise matrices with a specific trace value, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division, unicode_literals, with_statement\n",
    "import numpy as np\n",
    "\n",
    "from confidentlearning.util import value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noise_matrix_is_valid(noise_matrix, py, verbose = False):\n",
    "    '''Given a prior py = p(y=k), returns true if the given noise_matrix is a learnable matrix.\n",
    "    Learnability means that it is possible to achieve better than random performance, on average,\n",
    "    for the amount of noise in noise_matrix.'''\n",
    "\n",
    "    # Number of classes\n",
    "    K = len(py)\n",
    "\n",
    "    # Let's assume some number of training examples for code readability, \n",
    "    # but it doesn't matter what we choose as its not actually used.\n",
    "    N = float(10000)\n",
    "\n",
    "    ps = np.dot(noise_matrix, py) # P(y=k)\n",
    "\n",
    "    #P(s=k, y=k')\n",
    "    joint_noise = np.multiply(noise_matrix, py) # / float(N)\n",
    "\n",
    "    # Check that joint_probs is valid probability matrix\n",
    "    if not (abs(joint_noise.sum() - 1.0) < 1e-6):\n",
    "        return False\n",
    "\n",
    "    # Check that noise_matrix is a valid matrix\n",
    "    # i.e. check p(s=k)*p(y=k) < p(s=k, y=k)\n",
    "    for i in range(K):\n",
    "        C = N * joint_noise[i][i]\n",
    "        E1 = N * joint_noise[i].sum() - C\n",
    "        E2 = N * joint_noise.T[i].sum() - C\n",
    "        O = N - E1 - E2 - C\n",
    "        if verbose:\n",
    "            print(\"E1E2/C\", E1*E2/C,\"E1\", E1, \"E2\", E2, \"C\", C, \"|\", E1*E2/C + E1 + E2 + C, \"|\",  E1*E2/C, \"<\", O)\n",
    "            print(ps[i] * py[i], \"<\", joint_noise[i][i], \":\", ps[i] * py[i] < joint_noise[i][i])\n",
    "\n",
    "        if not (ps[i] * py[i] < joint_noise[i][i]):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_labels(y, noise_matrix, verbose=False):  \n",
    "    '''Generates noisy labels s (shape (N, 1)) from perfect labels y,\n",
    "    'exactly' yielding the provided noise_matrix between s and y.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    y : np.array (shape (N, 1))\n",
    "        Perfect labels, without any noise. Contains K distinct natural number\n",
    "        classes, e.g. 0, 1,..., K-1\n",
    "\n",
    "    noise_matrix : np.array of shape (K, K), K = number of classes \n",
    "        A conditional probablity matrix of the form P(s=k_s|y=k_y) containing\n",
    "        the fraction of examples in every class, labeled as every other class.\n",
    "        Assumes columns of noise_matrix sum to 1.'''\n",
    "  \n",
    "    # Number of classes\n",
    "    K = len(noise_matrix)\n",
    "\n",
    "    # Compute p(y=k)\n",
    "    py = value_counts(y) / float(len(y))\n",
    "\n",
    "    # Generate s\n",
    "    count_joint = (noise_matrix * py * len(y)).round().astype(int) # count(s and y)\n",
    "    s = np.array(y)\n",
    "    for k_s in range(K):\n",
    "        for k_y in range(K):\n",
    "            if k_s != k_y:\n",
    "                s[np.random.choice(np.where((s==k_y)&(y==k_y))[0], count_joint[k_s][k_y], replace=False)] = k_s\n",
    "\n",
    "    # Compute the actual noise matrix induced by s\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    counts = confusion_matrix(s, y).astype(float)\n",
    "    new_noise_matrix = counts / counts.sum(axis=0)\n",
    "\n",
    "    # Validate that s indeed produces the correct noise_matrix (or close to it)\n",
    "    if np.linalg.norm(noise_matrix - new_noise_matrix) > 1:\n",
    "        raise ValueError(\"s does not yield the same noise_matrix. \" +\n",
    "            \"The difference in norms is \" + str(np.linalg.norm(noise_matrix - new_noise_matrix)))\n",
    "\n",
    "    return s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_noise_matrix_from_trace(\n",
    "    K,                                      \n",
    "    trace,  \n",
    "    max_trace_prob=1.0,\n",
    "    min_trace_prob=1e-5,\n",
    "    max_noise_rate=1-1e-5,                                      \n",
    "    min_noise_rate=0.0,                                      \n",
    "    valid_noise_matrix=True, \n",
    "    py=None,\n",
    "    frac_zero_noise_rates=0.,\n",
    "): \n",
    "    '''Generates a K x K noise matrix P(s=k_s|y=k_y) with trace\n",
    "    as the np.mean(np.diagonal(noise_matrix)).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    K : int\n",
    "      Creates a noise matrix of shape (K, K). Implies there are \n",
    "      K classes for learning with noisy labels. \n",
    "\n",
    "    trace : float (0.0, 1.0]\n",
    "      Sum of diagonal entries of np.array of random probabilites that is returned.\n",
    "\n",
    "    max_trace_prob : float (0.0, 1.0]\n",
    "      Maximum probability of any entry in the trace of the return matrix.\n",
    "\n",
    "    min_trace_prob : float [0.0, 1.0)\n",
    "      Minimum probability of any entry in the trace of the return matrix.\n",
    "\n",
    "    max_noise_rate : float (0.0, 1.0]\n",
    "      Maximum noise_rate (non-digonal entry) in the returned np.array.\n",
    "\n",
    "    min_noise_rate : float [0.0, 1.0)\n",
    "      Minimum noise_rate (non-digonal entry) in the returned np.array.\n",
    "\n",
    "    valid_noise_matrix : bool\n",
    "      If True, returns a matrix having all necessary conditions for\n",
    "      learning with noisy labels. In particular, p(y=k)p(s=k) < p(y=k,s=k)\n",
    "      is satisfied. This requires that Trace > 1.\n",
    "\n",
    "    py : np.array (shape (K, 1))\n",
    "      The fraction (prior probability) of each true, hidden class label, P(y = k).\n",
    "      REQUIRED when valid_noise_matrix == True.\n",
    "\n",
    "    frac_zero_noise_rates : float\n",
    "      The fraction of the n*(n-1) noise rates that will be set to 0. Note that if\n",
    "      you set a high trace, it may be impossible to also have a low\n",
    "      fraction of zero noise rates without forcing all non-\"1\" diagonal values. \n",
    "      Instead, when this happens we only guarantee to produce a noise matrix with\n",
    "      frac_zero_noise_rates **or higher**. The opposite occurs with a small trace.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    np.array (shape (K, K)) \n",
    "      noise matrix P(s=k_s|y=k_y) with trace \n",
    "      as the np.sum(np.diagonal(noise_matrix)).\n",
    "      This a conditional probability matrix and a\n",
    "      left stochastic matrix.'''\n",
    "\n",
    "\n",
    "    if valid_noise_matrix and trace <= 1:\n",
    "        raise ValueError(\"trace > 1 is necessary for a\" +\n",
    "              \" valid noise matrix to be returned (valid_noise_matrix == True)\")\n",
    "    \n",
    "    if valid_noise_matrix and py is None:\n",
    "        raise ValueError(\"py must be provided (not None) if the input parameter\" +\n",
    "              \" valid_noise_matrix == True\")\n",
    "  \n",
    "    while True:\n",
    "        noise_matrix = np.zeros(shape=(K, K))\n",
    "        \n",
    "        # Randomly generate noise_matrix diagonal.\n",
    "        nm_diagonal = generate_n_rand_probabilities_that_sum_to_m(\n",
    "            n=K, \n",
    "            m=trace, \n",
    "            max_prob=max_trace_prob, \n",
    "            min_prob=min_trace_prob,\n",
    "        )\n",
    "        np.fill_diagonal(noise_matrix, nm_diagonal)\n",
    "        \n",
    "        # Randomly distribute number of zero-noise-rates across columns\n",
    "        num_col_with_noise = K - np.count_nonzero(1 == nm_diagonal)\n",
    "        num_zero_noise_rates = int(K * (K - 1) * frac_zero_noise_rates)\n",
    "        # Remove zeros already in [1,0,..,0] columns\n",
    "        num_zero_noise_rates -= (K - num_col_with_noise) * (K - 1) \n",
    "        num_zero_noise_rates = np.maximum(num_zero_noise_rates, 0) # Prevent negative\n",
    "        num_zero_noise_rates_per_col = randomly_distribute_N_balls_into_K_bins(\n",
    "            N = num_zero_noise_rates,\n",
    "            K = num_col_with_noise,\n",
    "            max_balls_per_bin = K - 2, # 2 = one for diagonal, and one to sum to 1\n",
    "            min_balls_per_bin = 0,\n",
    "        ) if K > 2 else np.array([1,1]) # special case for K = 2\n",
    "        stack_nonzero_noise_rates_per_col = list(K - 1 - num_zero_noise_rates_per_col)[::-1]\n",
    "        # Randomly generate noise rates for columns with noise.\n",
    "        for col in np.arange(K)[nm_diagonal != 1]:\n",
    "            num_noise = stack_nonzero_noise_rates_per_col.pop()\n",
    "            # Generate num_noise noise_rates for the given column.\n",
    "            noise_rates_col = list(generate_n_rand_probabilities_that_sum_to_m(\n",
    "                n=num_noise, \n",
    "                m=1-nm_diagonal[col], \n",
    "                max_prob=max_noise_rate, \n",
    "                min_prob=min_noise_rate,\n",
    "            ))\n",
    "            # Randomly select which rows of the noisy column to assign the random noise rates\n",
    "            rows = np.random.choice([row for row in range(K) if row!=col], num_noise, replace=False)\n",
    "            for row in rows:\n",
    "                noise_matrix[row][col] = noise_rates_col.pop()\n",
    "        if not valid_noise_matrix or noise_matrix_is_valid(noise_matrix, py):\n",
    "            break\n",
    "      \n",
    "    return noise_matrix\n",
    "\n",
    "\n",
    "def generate_n_rand_probabilities_that_sum_to_m(\n",
    "    n, \n",
    "    m, \n",
    "    max_prob = 1.0, \n",
    "    min_prob = 0.0,\n",
    "):\n",
    "    '''When min_prob=0 and max_prob = 1.0, this method is deprecated.\n",
    "    Instead use np.random.dirichlet(np.ones(n))*m\n",
    "\n",
    "    Generates 'n' random probabilities that sum to 'm'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    n : int\n",
    "      Length of np.array of random probabilities to be returned. \n",
    "\n",
    "    m : float\n",
    "      Sum of np.array of random probabilites that is returned.\n",
    "\n",
    "    max_prob : float (0.0, 1.0] | Default value is 1.0\n",
    "      Maximum probability of any entry in the returned np.array.\n",
    "\n",
    "    min_prob : float [0.0, 1.0) | Default value is 0.0\n",
    "      Minimum probability of any entry in the returned np.array.'''\n",
    "  \n",
    "    epsilon = 1e-8 # Imprecision allowed for inequalities with floats\n",
    "\n",
    "    if n == 0:\n",
    "        return np.array([])    \n",
    "    if (max_prob + epsilon) < m / float(n):\n",
    "        raise ValueError(\"max_prob must be greater or equal to m / n, but \" +\n",
    "                         \"max_prob = \"+str(max_prob)+\", m = \"+str(m)+\", n = \" +\n",
    "                         str(n)+\", m / n = \"+str(m/float(n)))\n",
    "    if min_prob > (m + epsilon) / float(n):\n",
    "        raise ValueError(\"min_prob must be less or equal to m / n, but \" +\n",
    "                         \"max_prob = \"+str(max_prob)+\", m = \"+str(m)+\", n = \" +\n",
    "                         str(n)+\", m / n = \"+str(m/float(n)))\n",
    "    if min_prob >= (max_prob + epsilon):\n",
    "        raise ValueError(\"min_prob must be less than max_prob, but \" +\n",
    "                         \"max_prob = \"+str(max_prob)+\", m = \"+str(m)+\", n = \" +\n",
    "                         str(n)+\", m / n = \"+str(m/float(n)))\n",
    "\n",
    "    # When max_prob = 1, min_prob = 0, the following two lines are equivalent to:\n",
    "    #   intermediate = np.sort(np.append(np.random.uniform(0, 1, n-1), [0, 1]))\n",
    "    #   result = (intermediate[1:] - intermediate[:-1]) * m\n",
    "    result = np.random.dirichlet(np.ones(n))*m\n",
    "\n",
    "    max_val = max(result) \n",
    "    while max_val > (max_prob + epsilon):\n",
    "        result[np.argmin(result)] = min(result) + (max_val - max_prob)\n",
    "        result[np.argmax(result)] = max_prob   \n",
    "        max_val = max(result)\n",
    "\n",
    "    min_val = min(result)\n",
    "    while min_val < (min_prob - epsilon):\n",
    "        result[np.argmax(result)] = max(result) - (min_prob - min_val)\n",
    "        result[np.argmin(result)] = min_prob   \n",
    "        min_val = min(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def randomly_distribute_N_balls_into_K_bins(\n",
    "    N, # int\n",
    "    K, # int\n",
    "    max_balls_per_bin = None,\n",
    "    min_balls_per_bin = None,\n",
    "):\n",
    "    '''Returns a uniformly random numpy integer array of length N that sums to K.'''\n",
    "    \n",
    "    if N == 0:\n",
    "        return np.zeros(K, dtype=int)\n",
    "    if max_balls_per_bin is None:\n",
    "        max_balls_per_bin = N\n",
    "    else:\n",
    "        max_balls_per_bin = min(max_balls_per_bin, N)\n",
    "    if min_balls_per_bin is None:\n",
    "        min_balls_per_bin = 0\n",
    "    else:\n",
    "        min_balls_per_bin = min(min_balls_per_bin, N/K)\n",
    "    if N/float(K) > max_balls_per_bin:\n",
    "        N = max_balls_per_bin * K\n",
    "    \n",
    "    arr = np.round(generate_n_rand_probabilities_that_sum_to_m(\n",
    "        n = K, \n",
    "        m = 1, \n",
    "        max_prob = max_balls_per_bin/float(N),\n",
    "        min_prob = min_balls_per_bin/float(N),\n",
    "    ) * N)\n",
    "    while sum(arr) != N:\n",
    "        while sum(arr) > N:\n",
    "            arr[np.argmax(arr)] -= 1\n",
    "        while sum(arr) < N:\n",
    "            arr[np.argmin(arr)] += 1\n",
    "    return arr.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deprecated functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise_matrix(\n",
    "    K,\n",
    "    max_noise_rate = 1.0,\n",
    "    frac_zero_noise_rates = 0.0,\n",
    "    verbose = False,\n",
    "):\n",
    "    '''DEPRECATED - Use generate_noise_matrix_from_trace()\n",
    "\n",
    "    Generates a noise matrix by randomly assigning noise rates\n",
    "    up to max_noise_rate, then setting noise rates to zero until\n",
    "    zero until P(s!=k|s=k) < 1 is satisified. Additionally,\n",
    "    frac_zero_noise_rates are set to zero.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    K : int\n",
    "      Creates a noise matrix of shape (K, K). Implies there are \n",
    "      K classes for learning with noisy labels. \n",
    "\n",
    "    max_noise_rate : float\n",
    "      Smaller ---> easier learning problem (less noise)\n",
    "\n",
    "    frac_zero_noise_rates : float\n",
    "      Make problem more tractable by making a fraction of noise rates zero.\n",
    "      Larger --> Easier learning problem\n",
    "\n",
    "    prob_y : np.array of floats\n",
    "      P(y=k). Sums to 1.'''\n",
    "    \n",
    "    # Init noise matrix to be random values from (0, max_noise_rate)\n",
    "    # P(s=k|y=k')\n",
    "    noise_matrix = np.random.rand(K,K) * max_noise_rate\n",
    "\n",
    "    # Round all noise rates \n",
    "    noise_matrix = noise_matrix.round(2)\n",
    "\n",
    "    # Initialize all P(s=k|y=k) = 0\n",
    "    for i in range(K):\n",
    "        noise_matrix[i][i] = 0.0\n",
    "\n",
    "    # Compute sum for each column\n",
    "    col_sum = noise_matrix.sum(axis=0)\n",
    "\n",
    "    # For each column, randomly set noise rates to zero until P(s!=k|s=k) < 1.\n",
    "    for y in range(K): # col\n",
    "        col = noise_matrix.T[y]\n",
    "        col_sum = np.sum(col)\n",
    "        while col_sum >= 1:\n",
    "            non_zero_indices = np.arange(K)[col!=0]\n",
    "            s = np.random.choice(non_zero_indices)\n",
    "            noise_matrix[s][y] = 0.0\n",
    "            col = noise_matrix.T[y]\n",
    "            col_sum = np.sum(col)\n",
    "\n",
    "    # Set frac_zero_noise_rates of the noise rates to 0 for increased tractability.\n",
    "    for s in range(K):\n",
    "        for y in range(K):\n",
    "            if np.random.rand() < frac_zero_noise_rates:\n",
    "                noise_matrix[s][y] = 0\n",
    "\n",
    "    # Compute sum for each column\n",
    "    col_sum = noise_matrix.sum(axis=0)\n",
    "\n",
    "    # Normalize each column such that P(s=k|y=k) = 1 - P(s!=k|s=k)\n",
    "    for i in range(K):\n",
    "        noise_matrix[i][i] = 1 - col_sum[i]\n",
    "  \n",
    "    if verbose:\n",
    "        print(\"Average trace of noise matrix is\", np.trace(noise_matrix) / float(K))\n",
    "    \n",
    "    return noise_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
